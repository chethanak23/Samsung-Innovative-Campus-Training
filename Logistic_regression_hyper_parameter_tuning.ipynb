{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chethanak23/Samsung-Innovative-Campus-Training/blob/main/Logistic_regression_hyper_parameter_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DXlqLT5y7Rl4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a sample dataset (e.g., breast cancer dataset)\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target"
      ],
      "metadata": {
        "id": "UHZ55nzvZ57E"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "z_K11Di_Z77l"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Logistic Regression model\n",
        "model = LogisticRegression(random_state=42)\n"
      ],
      "metadata": {
        "id": "b1WrSo8RaA0W"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_params()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0-koxPFadiQ",
        "outputId": "2578c631-0a62-4738-b172-179b29033062"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 1.0,\n",
              " 'class_weight': None,\n",
              " 'dual': False,\n",
              " 'fit_intercept': True,\n",
              " 'intercept_scaling': 1,\n",
              " 'l1_ratio': None,\n",
              " 'max_iter': 100,\n",
              " 'multi_class': 'deprecated',\n",
              " 'n_jobs': None,\n",
              " 'penalty': 'l2',\n",
              " 'random_state': 42,\n",
              " 'solver': 'lbfgs',\n",
              " 'tol': 0.0001,\n",
              " 'verbose': 0,\n",
              " 'warm_start': False}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the hyperparameter grid to search\n",
        "param_grid = {\n",
        "    'C': [0.001, 0.01, 0.1],\n",
        "    'solver': ['liblinear', 'lbfgs'],\n",
        "    'class_weight': [None, 'balanced']\n",
        "}\n"
      ],
      "metadata": {
        "id": "1K3DdqUtaB-L"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "help(param_grid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W05KFUExbz8n",
        "outputId": "aa319d07-9864-4deb-b1dc-710a95c10f6e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on dict object:\n",
            "\n",
            "class dict(object)\n",
            " |  dict() -> new empty dictionary\n",
            " |  dict(mapping) -> new dictionary initialized from a mapping object's\n",
            " |      (key, value) pairs\n",
            " |  dict(iterable) -> new dictionary initialized as if via:\n",
            " |      d = {}\n",
            " |      for k, v in iterable:\n",
            " |          d[k] = v\n",
            " |  dict(**kwargs) -> new dictionary initialized with the name=value pairs\n",
            " |      in the keyword argument list.  For example:  dict(one=1, two=2)\n",
            " |  \n",
            " |  Built-in subclasses:\n",
            " |      StgDict\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __contains__(self, key, /)\n",
            " |      True if the dictionary has the specified key, else False.\n",
            " |  \n",
            " |  __delitem__(self, key, /)\n",
            " |      Delete self[key].\n",
            " |  \n",
            " |  __eq__(self, value, /)\n",
            " |      Return self==value.\n",
            " |  \n",
            " |  __ge__(self, value, /)\n",
            " |      Return self>=value.\n",
            " |  \n",
            " |  __getattribute__(self, name, /)\n",
            " |      Return getattr(self, name).\n",
            " |  \n",
            " |  __getitem__(...)\n",
            " |      x.__getitem__(y) <==> x[y]\n",
            " |  \n",
            " |  __gt__(self, value, /)\n",
            " |      Return self>value.\n",
            " |  \n",
            " |  __init__(self, /, *args, **kwargs)\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  __ior__(self, value, /)\n",
            " |      Return self|=value.\n",
            " |  \n",
            " |  __iter__(self, /)\n",
            " |      Implement iter(self).\n",
            " |  \n",
            " |  __le__(self, value, /)\n",
            " |      Return self<=value.\n",
            " |  \n",
            " |  __len__(self, /)\n",
            " |      Return len(self).\n",
            " |  \n",
            " |  __lt__(self, value, /)\n",
            " |      Return self<value.\n",
            " |  \n",
            " |  __ne__(self, value, /)\n",
            " |      Return self!=value.\n",
            " |  \n",
            " |  __or__(self, value, /)\n",
            " |      Return self|value.\n",
            " |  \n",
            " |  __repr__(self, /)\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  __reversed__(self, /)\n",
            " |      Return a reverse iterator over the dict keys.\n",
            " |  \n",
            " |  __ror__(self, value, /)\n",
            " |      Return value|self.\n",
            " |  \n",
            " |  __setitem__(self, key, value, /)\n",
            " |      Set self[key] to value.\n",
            " |  \n",
            " |  __sizeof__(...)\n",
            " |      D.__sizeof__() -> size of D in memory, in bytes\n",
            " |  \n",
            " |  clear(...)\n",
            " |      D.clear() -> None.  Remove all items from D.\n",
            " |  \n",
            " |  copy(...)\n",
            " |      D.copy() -> a shallow copy of D\n",
            " |  \n",
            " |  get(self, key, default=None, /)\n",
            " |      Return the value for key if key is in the dictionary, else default.\n",
            " |  \n",
            " |  items(...)\n",
            " |      D.items() -> a set-like object providing a view on D's items\n",
            " |  \n",
            " |  keys(...)\n",
            " |      D.keys() -> a set-like object providing a view on D's keys\n",
            " |  \n",
            " |  pop(...)\n",
            " |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
            " |      \n",
            " |      If the key is not found, return the default if given; otherwise,\n",
            " |      raise a KeyError.\n",
            " |  \n",
            " |  popitem(self, /)\n",
            " |      Remove and return a (key, value) pair as a 2-tuple.\n",
            " |      \n",
            " |      Pairs are returned in LIFO (last-in, first-out) order.\n",
            " |      Raises KeyError if the dict is empty.\n",
            " |  \n",
            " |  setdefault(self, key, default=None, /)\n",
            " |      Insert key with a value of default if key is not in the dictionary.\n",
            " |      \n",
            " |      Return the value for key if key is in the dictionary, else default.\n",
            " |  \n",
            " |  update(...)\n",
            " |      D.update([E, ]**F) -> None.  Update D from dict/iterable E and F.\n",
            " |      If E is present and has a .keys() method, then does:  for k in E: D[k] = E[k]\n",
            " |      If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\n",
            " |      In either case, this is followed by: for k in F:  D[k] = F[k]\n",
            " |  \n",
            " |  values(...)\n",
            " |      D.values() -> an object providing a view on D's values\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods defined here:\n",
            " |  \n",
            " |  __class_getitem__(...)\n",
            " |      See PEP 585\n",
            " |  \n",
            " |  fromkeys(iterable, value=None, /)\n",
            " |      Create a new dictionary with keys from iterable and values set to value.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Static methods defined here:\n",
            " |  \n",
            " |  __new__(*args, **kwargs)\n",
            " |      Create and return a new object.  See help(type) for accurate signature.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes defined here:\n",
            " |  \n",
            " |  __hash__ = None\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(GridSearchCV)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52cz3cr0b76O",
        "outputId": "dbfd16b2-99a0-4671-aa19-f364e2887343"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on class GridSearchCV in module sklearn.model_selection._search:\n",
            "\n",
            "class GridSearchCV(BaseSearchCV)\n",
            " |  GridSearchCV(estimator, param_grid, *, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
            " |  \n",
            " |  Exhaustive search over specified parameter values for an estimator.\n",
            " |  \n",
            " |  Important members are fit, predict.\n",
            " |  \n",
            " |  GridSearchCV implements a \"fit\" and a \"score\" method.\n",
            " |  It also implements \"score_samples\", \"predict\", \"predict_proba\",\n",
            " |  \"decision_function\", \"transform\" and \"inverse_transform\" if they are\n",
            " |  implemented in the estimator used.\n",
            " |  \n",
            " |  The parameters of the estimator used to apply these methods are optimized\n",
            " |  by cross-validated grid-search over a parameter grid.\n",
            " |  \n",
            " |  Read more in the :ref:`User Guide <grid_search>`.\n",
            " |  \n",
            " |  Parameters\n",
            " |  ----------\n",
            " |  estimator : estimator object\n",
            " |      This is assumed to implement the scikit-learn estimator interface.\n",
            " |      Either estimator needs to provide a ``score`` function,\n",
            " |      or ``scoring`` must be passed.\n",
            " |  \n",
            " |  param_grid : dict or list of dictionaries\n",
            " |      Dictionary with parameters names (`str`) as keys and lists of\n",
            " |      parameter settings to try as values, or a list of such\n",
            " |      dictionaries, in which case the grids spanned by each dictionary\n",
            " |      in the list are explored. This enables searching over any sequence\n",
            " |      of parameter settings.\n",
            " |  \n",
            " |  scoring : str, callable, list, tuple or dict, default=None\n",
            " |      Strategy to evaluate the performance of the cross-validated model on\n",
            " |      the test set.\n",
            " |  \n",
            " |      If `scoring` represents a single score, one can use:\n",
            " |  \n",
            " |      - a single string (see :ref:`scoring_parameter`);\n",
            " |      - a callable (see :ref:`scoring_callable`) that returns a single value.\n",
            " |  \n",
            " |      If `scoring` represents multiple scores, one can use:\n",
            " |  \n",
            " |      - a list or tuple of unique strings;\n",
            " |      - a callable returning a dictionary where the keys are the metric\n",
            " |        names and the values are the metric scores;\n",
            " |      - a dictionary with metric names as keys and callables as values.\n",
            " |  \n",
            " |      See :ref:`multimetric_grid_search` for an example.\n",
            " |  \n",
            " |  n_jobs : int, default=None\n",
            " |      Number of jobs to run in parallel.\n",
            " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
            " |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
            " |      for more details.\n",
            " |  \n",
            " |      .. versionchanged:: v0.20\n",
            " |         `n_jobs` default changed from 1 to None\n",
            " |  \n",
            " |  refit : bool, str, or callable, default=True\n",
            " |      Refit an estimator using the best found parameters on the whole\n",
            " |      dataset.\n",
            " |  \n",
            " |      For multiple metric evaluation, this needs to be a `str` denoting the\n",
            " |      scorer that would be used to find the best parameters for refitting\n",
            " |      the estimator at the end.\n",
            " |  \n",
            " |      Where there are considerations other than maximum score in\n",
            " |      choosing a best estimator, ``refit`` can be set to a function which\n",
            " |      returns the selected ``best_index_`` given ``cv_results_``. In that\n",
            " |      case, the ``best_estimator_`` and ``best_params_`` will be set\n",
            " |      according to the returned ``best_index_`` while the ``best_score_``\n",
            " |      attribute will not be available.\n",
            " |  \n",
            " |      The refitted estimator is made available at the ``best_estimator_``\n",
            " |      attribute and permits using ``predict`` directly on this\n",
            " |      ``GridSearchCV`` instance.\n",
            " |  \n",
            " |      Also for multiple metric evaluation, the attributes ``best_index_``,\n",
            " |      ``best_score_`` and ``best_params_`` will only be available if\n",
            " |      ``refit`` is set and all of them will be determined w.r.t this specific\n",
            " |      scorer.\n",
            " |  \n",
            " |      See ``scoring`` parameter to know more about multiple metric\n",
            " |      evaluation.\n",
            " |  \n",
            " |      See :ref:`sphx_glr_auto_examples_model_selection_plot_grid_search_digits.py`\n",
            " |      to see how to design a custom selection strategy using a callable\n",
            " |      via `refit`.\n",
            " |  \n",
            " |      .. versionchanged:: 0.20\n",
            " |          Support for callable added.\n",
            " |  \n",
            " |  cv : int, cross-validation generator or an iterable, default=None\n",
            " |      Determines the cross-validation splitting strategy.\n",
            " |      Possible inputs for cv are:\n",
            " |  \n",
            " |      - None, to use the default 5-fold cross validation,\n",
            " |      - integer, to specify the number of folds in a `(Stratified)KFold`,\n",
            " |      - :term:`CV splitter`,\n",
            " |      - An iterable yielding (train, test) splits as arrays of indices.\n",
            " |  \n",
            " |      For integer/None inputs, if the estimator is a classifier and ``y`` is\n",
            " |      either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
            " |      other cases, :class:`KFold` is used. These splitters are instantiated\n",
            " |      with `shuffle=False` so the splits will be the same across calls.\n",
            " |  \n",
            " |      Refer :ref:`User Guide <cross_validation>` for the various\n",
            " |      cross-validation strategies that can be used here.\n",
            " |  \n",
            " |      .. versionchanged:: 0.22\n",
            " |          ``cv`` default value if None changed from 3-fold to 5-fold.\n",
            " |  \n",
            " |  verbose : int\n",
            " |      Controls the verbosity: the higher, the more messages.\n",
            " |  \n",
            " |      - >1 : the computation time for each fold and parameter candidate is\n",
            " |        displayed;\n",
            " |      - >2 : the score is also displayed;\n",
            " |      - >3 : the fold and candidate parameter indexes are also displayed\n",
            " |        together with the starting time of the computation.\n",
            " |  \n",
            " |  pre_dispatch : int, or str, default='2*n_jobs'\n",
            " |      Controls the number of jobs that get dispatched during parallel\n",
            " |      execution. Reducing this number can be useful to avoid an\n",
            " |      explosion of memory consumption when more jobs get dispatched\n",
            " |      than CPUs can process. This parameter can be:\n",
            " |  \n",
            " |      - None, in which case all the jobs are immediately created and spawned. Use\n",
            " |        this for lightweight and fast-running jobs, to avoid delays due to on-demand\n",
            " |        spawning of the jobs\n",
            " |      - An int, giving the exact number of total jobs that are spawned\n",
            " |      - A str, giving an expression as a function of n_jobs, as in '2*n_jobs'\n",
            " |  \n",
            " |  error_score : 'raise' or numeric, default=np.nan\n",
            " |      Value to assign to the score if an error occurs in estimator fitting.\n",
            " |      If set to 'raise', the error is raised. If a numeric value is given,\n",
            " |      FitFailedWarning is raised. This parameter does not affect the refit\n",
            " |      step, which will always raise the error.\n",
            " |  \n",
            " |  return_train_score : bool, default=False\n",
            " |      If ``False``, the ``cv_results_`` attribute will not include training\n",
            " |      scores.\n",
            " |      Computing training scores is used to get insights on how different\n",
            " |      parameter settings impact the overfitting/underfitting trade-off.\n",
            " |      However computing the scores on the training set can be computationally\n",
            " |      expensive and is not strictly required to select the parameters that\n",
            " |      yield the best generalization performance.\n",
            " |  \n",
            " |      .. versionadded:: 0.19\n",
            " |  \n",
            " |      .. versionchanged:: 0.21\n",
            " |          Default value was changed from ``True`` to ``False``\n",
            " |  \n",
            " |  Attributes\n",
            " |  ----------\n",
            " |  cv_results_ : dict of numpy (masked) ndarrays\n",
            " |      A dict with keys as column headers and values as columns, that can be\n",
            " |      imported into a pandas ``DataFrame``.\n",
            " |  \n",
            " |      For instance the below given table\n",
            " |  \n",
            " |      +------------+-----------+------------+-----------------+---+---------+\n",
            " |      |param_kernel|param_gamma|param_degree|split0_test_score|...|rank_t...|\n",
            " |      +============+===========+============+=================+===+=========+\n",
            " |      |  'poly'    |     --    |      2     |       0.80      |...|    2    |\n",
            " |      +------------+-----------+------------+-----------------+---+---------+\n",
            " |      |  'poly'    |     --    |      3     |       0.70      |...|    4    |\n",
            " |      +------------+-----------+------------+-----------------+---+---------+\n",
            " |      |  'rbf'     |     0.1   |     --     |       0.80      |...|    3    |\n",
            " |      +------------+-----------+------------+-----------------+---+---------+\n",
            " |      |  'rbf'     |     0.2   |     --     |       0.93      |...|    1    |\n",
            " |      +------------+-----------+------------+-----------------+---+---------+\n",
            " |  \n",
            " |      will be represented by a ``cv_results_`` dict of::\n",
            " |  \n",
            " |          {\n",
            " |          'param_kernel': masked_array(data = ['poly', 'poly', 'rbf', 'rbf'],\n",
            " |                                       mask = [False False False False]...)\n",
            " |          'param_gamma': masked_array(data = [-- -- 0.1 0.2],\n",
            " |                                      mask = [ True  True False False]...),\n",
            " |          'param_degree': masked_array(data = [2.0 3.0 -- --],\n",
            " |                                       mask = [False False  True  True]...),\n",
            " |          'split0_test_score'  : [0.80, 0.70, 0.80, 0.93],\n",
            " |          'split1_test_score'  : [0.82, 0.50, 0.70, 0.78],\n",
            " |          'mean_test_score'    : [0.81, 0.60, 0.75, 0.85],\n",
            " |          'std_test_score'     : [0.01, 0.10, 0.05, 0.08],\n",
            " |          'rank_test_score'    : [2, 4, 3, 1],\n",
            " |          'split0_train_score' : [0.80, 0.92, 0.70, 0.93],\n",
            " |          'split1_train_score' : [0.82, 0.55, 0.70, 0.87],\n",
            " |          'mean_train_score'   : [0.81, 0.74, 0.70, 0.90],\n",
            " |          'std_train_score'    : [0.01, 0.19, 0.00, 0.03],\n",
            " |          'mean_fit_time'      : [0.73, 0.63, 0.43, 0.49],\n",
            " |          'std_fit_time'       : [0.01, 0.02, 0.01, 0.01],\n",
            " |          'mean_score_time'    : [0.01, 0.06, 0.04, 0.04],\n",
            " |          'std_score_time'     : [0.00, 0.00, 0.00, 0.01],\n",
            " |          'params'             : [{'kernel': 'poly', 'degree': 2}, ...],\n",
            " |          }\n",
            " |  \n",
            " |      NOTE\n",
            " |  \n",
            " |      The key ``'params'`` is used to store a list of parameter\n",
            " |      settings dicts for all the parameter candidates.\n",
            " |  \n",
            " |      The ``mean_fit_time``, ``std_fit_time``, ``mean_score_time`` and\n",
            " |      ``std_score_time`` are all in seconds.\n",
            " |  \n",
            " |      For multi-metric evaluation, the scores for all the scorers are\n",
            " |      available in the ``cv_results_`` dict at the keys ending with that\n",
            " |      scorer's name (``'_<scorer_name>'``) instead of ``'_score'`` shown\n",
            " |      above. ('split0_test_precision', 'mean_train_precision' etc.)\n",
            " |  \n",
            " |  best_estimator_ : estimator\n",
            " |      Estimator that was chosen by the search, i.e. estimator\n",
            " |      which gave highest score (or smallest loss if specified)\n",
            " |      on the left out data. Not available if ``refit=False``.\n",
            " |  \n",
            " |      See ``refit`` parameter for more information on allowed values.\n",
            " |  \n",
            " |  best_score_ : float\n",
            " |      Mean cross-validated score of the best_estimator\n",
            " |  \n",
            " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
            " |      specified.\n",
            " |  \n",
            " |      This attribute is not available if ``refit`` is a function.\n",
            " |  \n",
            " |  best_params_ : dict\n",
            " |      Parameter setting that gave the best results on the hold out data.\n",
            " |  \n",
            " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
            " |      specified.\n",
            " |  \n",
            " |  best_index_ : int\n",
            " |      The index (of the ``cv_results_`` arrays) which corresponds to the best\n",
            " |      candidate parameter setting.\n",
            " |  \n",
            " |      The dict at ``search.cv_results_['params'][search.best_index_]`` gives\n",
            " |      the parameter setting for the best model, that gives the highest\n",
            " |      mean score (``search.best_score_``).\n",
            " |  \n",
            " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
            " |      specified.\n",
            " |  \n",
            " |  scorer_ : function or a dict\n",
            " |      Scorer function used on the held out data to choose the best\n",
            " |      parameters for the model.\n",
            " |  \n",
            " |      For multi-metric evaluation, this attribute holds the validated\n",
            " |      ``scoring`` dict which maps the scorer key to the scorer callable.\n",
            " |  \n",
            " |  n_splits_ : int\n",
            " |      The number of cross-validation splits (folds/iterations).\n",
            " |  \n",
            " |  refit_time_ : float\n",
            " |      Seconds used for refitting the best model on the whole dataset.\n",
            " |  \n",
            " |      This is present only if ``refit`` is not False.\n",
            " |  \n",
            " |      .. versionadded:: 0.20\n",
            " |  \n",
            " |  multimetric_ : bool\n",
            " |      Whether or not the scorers compute several metrics.\n",
            " |  \n",
            " |  classes_ : ndarray of shape (n_classes,)\n",
            " |      The classes labels. This is present only if ``refit`` is specified and\n",
            " |      the underlying estimator is a classifier.\n",
            " |  \n",
            " |  n_features_in_ : int\n",
            " |      Number of features seen during :term:`fit`. Only defined if\n",
            " |      `best_estimator_` is defined (see the documentation for the `refit`\n",
            " |      parameter for more details) and that `best_estimator_` exposes\n",
            " |      `n_features_in_` when fit.\n",
            " |  \n",
            " |      .. versionadded:: 0.24\n",
            " |  \n",
            " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
            " |      Names of features seen during :term:`fit`. Only defined if\n",
            " |      `best_estimator_` is defined (see the documentation for the `refit`\n",
            " |      parameter for more details) and that `best_estimator_` exposes\n",
            " |      `feature_names_in_` when fit.\n",
            " |  \n",
            " |      .. versionadded:: 1.0\n",
            " |  \n",
            " |  See Also\n",
            " |  --------\n",
            " |  ParameterGrid : Generates all the combinations of a hyperparameter grid.\n",
            " |  train_test_split : Utility function to split the data into a development\n",
            " |      set usable for fitting a GridSearchCV instance and an evaluation set\n",
            " |      for its final evaluation.\n",
            " |  sklearn.metrics.make_scorer : Make a scorer from a performance metric or\n",
            " |      loss function.\n",
            " |  \n",
            " |  Notes\n",
            " |  -----\n",
            " |  The parameters selected are those that maximize the score of the left out\n",
            " |  data, unless an explicit score is passed in which case it is used instead.\n",
            " |  \n",
            " |  If `n_jobs` was set to a value higher than one, the data is copied for each\n",
            " |  point in the grid (and not `n_jobs` times). This is done for efficiency\n",
            " |  reasons if individual jobs take very little time, but may raise errors if\n",
            " |  the dataset is large and not enough memory is available.  A workaround in\n",
            " |  this case is to set `pre_dispatch`. Then, the memory is copied only\n",
            " |  `pre_dispatch` many times. A reasonable value for `pre_dispatch` is `2 *\n",
            " |  n_jobs`.\n",
            " |  \n",
            " |  Examples\n",
            " |  --------\n",
            " |  >>> from sklearn import svm, datasets\n",
            " |  >>> from sklearn.model_selection import GridSearchCV\n",
            " |  >>> iris = datasets.load_iris()\n",
            " |  >>> parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
            " |  >>> svc = svm.SVC()\n",
            " |  >>> clf = GridSearchCV(svc, parameters)\n",
            " |  >>> clf.fit(iris.data, iris.target)\n",
            " |  GridSearchCV(estimator=SVC(),\n",
            " |               param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')})\n",
            " |  >>> sorted(clf.cv_results_.keys())\n",
            " |  ['mean_fit_time', 'mean_score_time', 'mean_test_score',...\n",
            " |   'param_C', 'param_kernel', 'params',...\n",
            " |   'rank_test_score', 'split0_test_score',...\n",
            " |   'split2_test_score', ...\n",
            " |   'std_fit_time', 'std_score_time', 'std_test_score']\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      GridSearchCV\n",
            " |      BaseSearchCV\n",
            " |      sklearn.base.MetaEstimatorMixin\n",
            " |      sklearn.base.BaseEstimator\n",
            " |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
            " |      sklearn.utils._metadata_requests._MetadataRequester\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, estimator, param_grid, *, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes defined here:\n",
            " |  \n",
            " |  __abstractmethods__ = frozenset()\n",
            " |  \n",
            " |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from BaseSearchCV:\n",
            " |  \n",
            " |  __sklearn_tags__(self)\n",
            " |  \n",
            " |  decision_function(self, X)\n",
            " |      Call decision_function on the estimator with the best found parameters.\n",
            " |      \n",
            " |      Only available if ``refit=True`` and the underlying estimator supports\n",
            " |      ``decision_function``.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : indexable, length n_samples\n",
            " |          Must fulfill the input assumptions of the\n",
            " |          underlying estimator.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      y_score : ndarray of shape (n_samples,) or (n_samples, n_classes)                 or (n_samples, n_classes * (n_classes-1) / 2)\n",
            " |          Result of the decision function for `X` based on the estimator with\n",
            " |          the best found parameters.\n",
            " |  \n",
            " |  fit(self, X, y=None, **params)\n",
            " |      Run fit with all sets of parameters.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      \n",
            " |      X : array-like of shape (n_samples, n_features) or (n_samples, n_samples)\n",
            " |          Training vectors, where `n_samples` is the number of samples and\n",
            " |          `n_features` is the number of features. For precomputed kernel or\n",
            " |          distance matrix, the expected shape of X is (n_samples, n_samples).\n",
            " |      \n",
            " |      y : array-like of shape (n_samples, n_output)             or (n_samples,), default=None\n",
            " |          Target relative to X for classification or regression;\n",
            " |          None for unsupervised learning.\n",
            " |      \n",
            " |      **params : dict of str -> object\n",
            " |          Parameters passed to the ``fit`` method of the estimator, the scorer,\n",
            " |          and the CV splitter.\n",
            " |      \n",
            " |          If a fit parameter is an array-like whose length is equal to\n",
            " |          `num_samples` then it will be split by cross-validation along with\n",
            " |          `X` and `y`. For example, the :term:`sample_weight` parameter is\n",
            " |          split because `len(sample_weights) = len(X)`. However, this behavior\n",
            " |          does not apply to `groups` which is passed to the splitter configured\n",
            " |          via the `cv` parameter of the constructor. Thus, `groups` is used\n",
            " |          *to perform the split* and determines which samples are\n",
            " |          assigned to the each side of the a split.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : object\n",
            " |          Instance of fitted estimator.\n",
            " |  \n",
            " |  get_metadata_routing(self)\n",
            " |      Get metadata routing of this object.\n",
            " |      \n",
            " |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
            " |      mechanism works.\n",
            " |      \n",
            " |      .. versionadded:: 1.4\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      routing : MetadataRouter\n",
            " |          A :class:`~sklearn.utils.metadata_routing.MetadataRouter` encapsulating\n",
            " |          routing information.\n",
            " |  \n",
            " |  inverse_transform(self, X=None, Xt=None)\n",
            " |      Call inverse_transform on the estimator with the best found params.\n",
            " |      \n",
            " |      Only available if the underlying estimator implements\n",
            " |      ``inverse_transform`` and ``refit=True``.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : indexable, length n_samples\n",
            " |          Must fulfill the input assumptions of the\n",
            " |          underlying estimator.\n",
            " |      \n",
            " |      Xt : indexable, length n_samples\n",
            " |          Must fulfill the input assumptions of the\n",
            " |          underlying estimator.\n",
            " |      \n",
            " |          .. deprecated:: 1.5\n",
            " |              `Xt` was deprecated in 1.5 and will be removed in 1.7. Use `X` instead.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      X : {ndarray, sparse matrix} of shape (n_samples, n_features)\n",
            " |          Result of the `inverse_transform` function for `Xt` based on the\n",
            " |          estimator with the best found parameters.\n",
            " |  \n",
            " |  predict(self, X)\n",
            " |      Call predict on the estimator with the best found parameters.\n",
            " |      \n",
            " |      Only available if ``refit=True`` and the underlying estimator supports\n",
            " |      ``predict``.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : indexable, length n_samples\n",
            " |          Must fulfill the input assumptions of the\n",
            " |          underlying estimator.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      y_pred : ndarray of shape (n_samples,)\n",
            " |          The predicted labels or values for `X` based on the estimator with\n",
            " |          the best found parameters.\n",
            " |  \n",
            " |  predict_log_proba(self, X)\n",
            " |      Call predict_log_proba on the estimator with the best found parameters.\n",
            " |      \n",
            " |      Only available if ``refit=True`` and the underlying estimator supports\n",
            " |      ``predict_log_proba``.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : indexable, length n_samples\n",
            " |          Must fulfill the input assumptions of the\n",
            " |          underlying estimator.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      y_pred : ndarray of shape (n_samples,) or (n_samples, n_classes)\n",
            " |          Predicted class log-probabilities for `X` based on the estimator\n",
            " |          with the best found parameters. The order of the classes\n",
            " |          corresponds to that in the fitted attribute :term:`classes_`.\n",
            " |  \n",
            " |  predict_proba(self, X)\n",
            " |      Call predict_proba on the estimator with the best found parameters.\n",
            " |      \n",
            " |      Only available if ``refit=True`` and the underlying estimator supports\n",
            " |      ``predict_proba``.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : indexable, length n_samples\n",
            " |          Must fulfill the input assumptions of the\n",
            " |          underlying estimator.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      y_pred : ndarray of shape (n_samples,) or (n_samples, n_classes)\n",
            " |          Predicted class probabilities for `X` based on the estimator with\n",
            " |          the best found parameters. The order of the classes corresponds\n",
            " |          to that in the fitted attribute :term:`classes_`.\n",
            " |  \n",
            " |  score(self, X, y=None, **params)\n",
            " |      Return the score on the given data, if the estimator has been refit.\n",
            " |      \n",
            " |      This uses the score defined by ``scoring`` where provided, and the\n",
            " |      ``best_estimator_.score`` method otherwise.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like of shape (n_samples, n_features)\n",
            " |          Input data, where `n_samples` is the number of samples and\n",
            " |          `n_features` is the number of features.\n",
            " |      \n",
            " |      y : array-like of shape (n_samples, n_output)             or (n_samples,), default=None\n",
            " |          Target relative to X for classification or regression;\n",
            " |          None for unsupervised learning.\n",
            " |      \n",
            " |      **params : dict\n",
            " |          Parameters to be passed to the underlying scorer(s).\n",
            " |      \n",
            " |          .. versionadded:: 1.4\n",
            " |              Only available if `enable_metadata_routing=True`. See\n",
            " |              :ref:`Metadata Routing User Guide <metadata_routing>` for more\n",
            " |              details.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      score : float\n",
            " |          The score defined by ``scoring`` if provided, and the\n",
            " |          ``best_estimator_.score`` method otherwise.\n",
            " |  \n",
            " |  score_samples(self, X)\n",
            " |      Call score_samples on the estimator with the best found parameters.\n",
            " |      \n",
            " |      Only available if ``refit=True`` and the underlying estimator supports\n",
            " |      ``score_samples``.\n",
            " |      \n",
            " |      .. versionadded:: 0.24\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : iterable\n",
            " |          Data to predict on. Must fulfill input requirements\n",
            " |          of the underlying estimator.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      y_score : ndarray of shape (n_samples,)\n",
            " |          The ``best_estimator_.score_samples`` method.\n",
            " |  \n",
            " |  transform(self, X)\n",
            " |      Call transform on the estimator with the best found parameters.\n",
            " |      \n",
            " |      Only available if the underlying estimator supports ``transform`` and\n",
            " |      ``refit=True``.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : indexable, length n_samples\n",
            " |          Must fulfill the input assumptions of the\n",
            " |          underlying estimator.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      Xt : {ndarray, sparse matrix} of shape (n_samples, n_features)\n",
            " |          `X` transformed in the new space based on the estimator with\n",
            " |          the best found parameters.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Readonly properties inherited from BaseSearchCV:\n",
            " |  \n",
            " |  classes_\n",
            " |      Class labels.\n",
            " |      \n",
            " |      Only available when `refit=True` and the estimator is a classifier.\n",
            " |  \n",
            " |  n_features_in_\n",
            " |      Number of features seen during :term:`fit`.\n",
            " |      \n",
            " |      Only available when `refit=True`.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from sklearn.base.MetaEstimatorMixin:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.BaseEstimator:\n",
            " |  \n",
            " |  __getstate__(self)\n",
            " |      Helper for pickle.\n",
            " |  \n",
            " |  __repr__(self, N_CHAR_MAX=700)\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  __setstate__(self, state)\n",
            " |  \n",
            " |  __sklearn_clone__(self)\n",
            " |  \n",
            " |  get_params(self, deep=True)\n",
            " |      Get parameters for this estimator.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      deep : bool, default=True\n",
            " |          If True, will return the parameters for this estimator and\n",
            " |          contained subobjects that are estimators.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      params : dict\n",
            " |          Parameter names mapped to their values.\n",
            " |  \n",
            " |  set_params(self, **params)\n",
            " |      Set the parameters of this estimator.\n",
            " |      \n",
            " |      The method works on simple estimators as well as on nested objects\n",
            " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
            " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
            " |      possible to update each component of a nested object.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      **params : dict\n",
            " |          Estimator parameters.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : estimator instance\n",
            " |          Estimator instance.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
            " |  \n",
            " |  __init_subclass__(**kwargs)\n",
            " |      Set the ``set_{method}_request`` methods.\n",
            " |      \n",
            " |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
            " |      looks for the information available in the set default values which are\n",
            " |      set using ``__metadata_request__*`` class attributes, or inferred\n",
            " |      from method signatures.\n",
            " |      \n",
            " |      The ``__metadata_request__*`` class attributes are used when a method\n",
            " |      does not explicitly accept a metadata through its arguments or if the\n",
            " |      developer would like to specify a request value for those metadata\n",
            " |      which are different from the default ``None``.\n",
            " |      \n",
            " |      References\n",
            " |      ----------\n",
            " |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Use GridSearchCV to find the best hyperparameters\n",
        "grid_search = GridSearchCV(model,\n",
        "                           param_grid,\n",
        "                           cv=5,\n",
        "                           scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "X0OZ6sAVZ_vG",
        "outputId": "91213181-872c-4710-85ee-68588d223256"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=LogisticRegression(random_state=42),\n",
              "             param_grid={'C': [0.001, 0.01, 0.1],\n",
              "                         'class_weight': [None, 'balanced'],\n",
              "                         'solver': ['liblinear', 'lbfgs']},\n",
              "             scoring='accuracy')"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(random_state=42),\n",
              "             param_grid={&#x27;C&#x27;: [0.001, 0.01, 0.1],\n",
              "                         &#x27;class_weight&#x27;: [None, &#x27;balanced&#x27;],\n",
              "                         &#x27;solver&#x27;: [&#x27;liblinear&#x27;, &#x27;lbfgs&#x27;]},\n",
              "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(random_state=42),\n",
              "             param_grid={&#x27;C&#x27;: [0.001, 0.01, 0.1],\n",
              "                         &#x27;class_weight&#x27;: [None, &#x27;balanced&#x27;],\n",
              "                         &#x27;solver&#x27;: [&#x27;liblinear&#x27;, &#x27;lbfgs&#x27;]},\n",
              "             scoring=&#x27;accuracy&#x27;)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: LogisticRegression</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=0.1, class_weight=&#x27;balanced&#x27;, random_state=42,\n",
              "                   solver=&#x27;liblinear&#x27;)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=0.1, class_weight=&#x27;balanced&#x27;, random_state=42,\n",
              "                   solver=&#x27;liblinear&#x27;)</pre></div> </div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Print the best hyperparameters and score\n",
        "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
        "print(\"Best cross-validation score:\", grid_search.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjhHHM3RZ-bR",
        "outputId": "a92f316b-89eb-4103-ea2d-5d028f298bc6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'solver': 'liblinear'}\n",
            "Best cross-validation score: 0.9362637362637363\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluate the model with the best hyperparameters on the test set\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Test accuracy:\", test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GWQi62vZ9K7",
        "outputId": "4b9de7f6-7427-4455-a298-76756b2634ce"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.9736842105263158\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZgE5A7oybUsZ"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}